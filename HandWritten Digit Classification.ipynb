{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b635762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Activation,Flatten \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Conv2D , MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "efca5bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 60,000 training and 10,000 testing datasets\n",
    "(x_train , y_train) , (x_test , y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15b1ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1] , cmap = 'gray')\n",
    "\n",
    "plt.title(y_train[1])\n",
    "\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccdfb8ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bba3fad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n"
     ]
    }
   ],
   "source": [
    "features_train = x_train.reshape(x_train.shape[0] , 28,28,1) # 1 for gray scale\n",
    "features_test = x_test.reshape(x_test.shape[0] , 28,28,1)\n",
    "\n",
    "features_train = features_train.astype('float32')\n",
    "features_test = features_test.astype('float32')\n",
    "\n",
    "#Normalization\n",
    "features_train/=255\n",
    "features_test/=255\n",
    "#within the range [0,1]\n",
    "\n",
    "#One Hot Encoding\n",
    "\n",
    "targets_train = np_utils.to_categorical(y_train ,10)\n",
    "targets_test = np_utils.to_categorical(y_test , 10)\n",
    " \n",
    "print(targets_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "466ebb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 26, 26, 32)       128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 12, 12, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 12, 12, 32)       128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10, 10, 64)        0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10, 10, 64)       256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 8, 8, 64)          0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               524800    \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 512)               0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 597,482\n",
      "Trainable params: 596,202\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32 , (3,3) , input_shape = (28,28,1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32 , (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64 , (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64 , (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dropout(0.3)) # 0.3 is the prob of dropping the neuron\n",
    "model.add(Dense(10 , activation = 'softmax'))\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4855bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 161s 340ms/step - loss: 0.0975 - accuracy: 0.9705 - val_loss: 0.1629 - val_accuracy: 0.9485\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 162s 346ms/step - loss: 0.0356 - accuracy: 0.9891 - val_loss: 0.0332 - val_accuracy: 0.9886\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 159s 340ms/step - loss: 0.0256 - accuracy: 0.9920 - val_loss: 0.0339 - val_accuracy: 0.9883\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 157s 334ms/step - loss: 0.0214 - accuracy: 0.9935 - val_loss: 0.0285 - val_accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 153s 326ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0264 - val_accuracy: 0.9915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x278b6703940>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'categorical_crossentropy' , optimizer = Adam(learning_rate = 0.001) , metrics = [\"accuracy\"])\n",
    "\n",
    "model.fit(features_train , targets_train , epochs = 5 , batch_size = 128 , validation_data = (features_test , targets_test) ,verbose = 1)\n",
    "# validation_data : Data on which to evaluate the loss and any model metrics at the end of each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a8701c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 8s 25ms/step - loss: 0.0264 - accuracy: 0.9915\n",
      "[0.02639009989798069, 0.9915000200271606]\n"
     ]
    }
   ],
   "source": [
    "print(model.evaluate(features_test , targets_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "520557d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 7s 23ms/step\n",
      "[[0. 0. 0. ... 1. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict(features_test).round())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb243a23",
   "metadata": {},
   "source": [
    "FITTING USING DATA AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cf2356",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(rotation_range = 7 , width_shift_range = 0.05 , shear_range = 0.3 , height_shift_range = 0.07 , zoom_range = 0.05)\n",
    "test_generator = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_generator.flow(features_train , targets_train , batch_size = 64)\n",
    "test_generator = train_generator.flow(features_test , targets_test , batch_size = 64)\n",
    "\n",
    "model.fit_generator(train_generator , steps_per_epoch = 60000//64 , epochs = 5 , valdiation_data = test_generator , validation_steps = 10000//64 )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
